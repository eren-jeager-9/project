{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa0f050",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af0d7f",
   "metadata": {},
   "source": [
    "Features\n",
    "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "- Vocal channel (01 = speech, 02 = song).\n",
    "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "- Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe300568",
   "metadata": {},
   "source": [
    "NB We considered only the speech videos (vocal channel=01) with both audio and video (modality=01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d260a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:37.510784Z",
     "start_time": "2023-01-01T17:27:37.486950Z"
    }
   },
   "outputs": [],
   "source": [
    "emotions = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}\n",
    "emotional_intensity = {1:'normal', 2:'strong'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bc976d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:13.200431Z",
     "start_time": "2023-01-01T17:27:10.028517Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d503e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:20.350634Z",
     "start_time": "2023-01-01T17:27:20.329824Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"Datasets/RAVDESS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526e8cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:27.666721Z",
     "start_time": "2023-01-01T17:27:27.647035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-01-01-01-01-01-01',\n",
       " '01-01-01-01-01-02-01',\n",
       " '01-01-01-01-02-01-01',\n",
       " '01-01-01-01-02-02-01',\n",
       " '01-01-02-01-01-01-01']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "feats = []\n",
    "labels = []\n",
    "paths = []\n",
    "\n",
    "for (dirpath, dirnames, fn) in os.walk(path):\n",
    "    for name in fn:\n",
    "        filename = name.split('.')[0]\n",
    "        feat = filename.split('-')[2:]\n",
    "        label = feat[0]\n",
    "        filenames.append(filename)\n",
    "        feats.append(feat)\n",
    "        labels.append(label)\n",
    "        paths.append(dirpath + '/' + filename)\n",
    "        \n",
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce701ade",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f05715f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:40.031915Z",
     "start_time": "2023-01-01T17:27:40.012195Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotional intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>actor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01-01-01-01-01-01</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-01-01-01-02-01</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-01-01-02-01-01</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-01-01-02-02-01</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-02-01-01-01-01</th>\n",
       "      <td>calm</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-08-01-02-02-24</th>\n",
       "      <td>surprise</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-08-02-01-01-24</th>\n",
       "      <td>surprise</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-08-02-01-02-24</th>\n",
       "      <td>surprise</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-08-02-02-01-24</th>\n",
       "      <td>surprise</td>\n",
       "      <td>strong</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-08-02-02-02-24</th>\n",
       "      <td>surprise</td>\n",
       "      <td>strong</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       emotion emotional intensity  statement  repetition  \\\n",
       "index                                                                       \n",
       "01-01-01-01-01-01-01   neutral              normal          1           1   \n",
       "01-01-01-01-01-02-01   neutral              normal          1           2   \n",
       "01-01-01-01-02-01-01   neutral              normal          2           1   \n",
       "01-01-01-01-02-02-01   neutral              normal          2           2   \n",
       "01-01-02-01-01-01-01      calm              normal          1           1   \n",
       "...                        ...                 ...        ...         ...   \n",
       "01-01-08-01-02-02-24  surprise              normal          2           2   \n",
       "01-01-08-02-01-01-24  surprise              strong          1           1   \n",
       "01-01-08-02-01-02-24  surprise              strong          1           2   \n",
       "01-01-08-02-02-01-24  surprise              strong          2           1   \n",
       "01-01-08-02-02-02-24  surprise              strong          2           2   \n",
       "\n",
       "                      actor  \n",
       "index                        \n",
       "01-01-01-01-01-01-01      1  \n",
       "01-01-01-01-01-02-01      1  \n",
       "01-01-01-01-02-01-01      1  \n",
       "01-01-01-01-02-02-01      1  \n",
       "01-01-02-01-01-01-01      1  \n",
       "...                     ...  \n",
       "01-01-08-01-02-02-24     24  \n",
       "01-01-08-02-01-01-24     24  \n",
       "01-01-08-02-01-02-24     24  \n",
       "01-01-08-02-02-01-24     24  \n",
       "01-01-08-02-02-02-24     24  \n",
       "\n",
       "[1440 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(feats, columns = ['emotion', 'emotional intensity', 'statement', 'repetition', 'actor']).astype(int)\n",
    "\n",
    "df['emotion'] = df['emotion'].map(emotions)\n",
    "df['emotional intensity'] = df['emotional intensity'].map(emotional_intensity)\n",
    "\n",
    "df['index'] = filenames\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f7368",
   "metadata": {},
   "source": [
    "## Export frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ae3e3",
   "metadata": {},
   "source": [
    "- one frame every skip=3 starting from the 21th frame\n",
    "- proportional resize to obtain height=224\n",
    "- saved as png with and name videoname_iframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7a032a1",
   "metadata": {},
   "source": [
    "### 398x224 normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955a9f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T18:28:26.762954Z",
     "start_time": "2023-01-01T18:28:26.754434Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    nframes_tot = 0\n",
    "    \n",
    "    for count, video in enumerate(zip(filenames, paths)):\n",
    "        # Gather all its frames\n",
    "        save_frames(video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames'), skip)\n",
    "        print(f\"Processed videos {count+1}/{len(paths)}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def save_frames(filename, input_path, output_path, skip):\n",
    "    # Initialize video reader\n",
    "    cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "    frames = []\n",
    "    count = 0\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    try:\n",
    "        # Loop through all frames\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if (count % skip == 0 and count > 20):\n",
    "                #print(frame.shape)\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, (398, 224))\n",
    "                cv2.imwrite(output_path + '/' + f'{filename}_{count}' + '.png', frame)\n",
    "            count += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c48ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T18:48:13.241324Z",
     "start_time": "2023-01-01T18:34:00.912543Z"
    }
   },
   "outputs": [],
   "source": [
    "prepare_all_videos(filenames, paths, skip=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a39bcd8f",
   "metadata": {},
   "source": [
    "### 224x224 black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    nframes_tot = 0\n",
    "    \n",
    "    for count, video in enumerate(zip(filenames, paths)):\n",
    "        # Gather all its frames\n",
    "        save_frames(video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames_black'), skip)\n",
    "        print(f\"Processed videos {count+1}/{len(paths)}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def save_frames(filename, input_path, output_path, skip):\n",
    "    # Initialize video reader\n",
    "    cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "    frames = []\n",
    "    count = 0\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    try:\n",
    "        # Loop through all frames\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if (count % skip == 0 and count > 20):\n",
    "                #print(frame.shape)\n",
    "                if not ret:\n",
    "                    break\n",
    "                #####\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                  # background from white to black\n",
    "                ret, thresh = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "                frame[thresh == 255] = 0\n",
    "                #####\n",
    "                frame = cv2.resize(frame, (398, 224))\n",
    "                frame = frame[0:224, 87:311]\n",
    "                cv2.imwrite(output_path + '/' + f'{filename}_{count}' + '.png', frame)\n",
    "            count += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_all_videos(filenames, paths, skip=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b84b0c65",
   "metadata": {},
   "source": [
    "### 224x224 only faces BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a08142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    nframes_tot = 0\n",
    "    \n",
    "    for count, video in enumerate(zip(filenames, paths)):\n",
    "        # Gather all its frames\n",
    "        save_frames(video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames_face_BW'), skip)\n",
    "        print(f\"Processed videos {count+1}/{len(paths)}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def save_frames(filename, input_path, output_path, skip):\n",
    "    # Initialize video reader\n",
    "    cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "    haar_cascade = cv2.CascadeClassifier('./Other/haarcascade_frontalface_default.xml')\n",
    "    frames = []\n",
    "    count = 0\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    try:\n",
    "        # Loop through all frames\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if (count % skip == 0 and count > 20):\n",
    "                #print(frame.shape)\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.12, minNeighbors=9)\n",
    "                # if len(faces) != 1:\n",
    "                    \n",
    "                if len(faces) == 0:\n",
    "                    faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.02, minNeighbors=9)\n",
    "                    if len(faces) == 0:\n",
    "                        raise Exception(f\"Still no faces {len(faces)} {filename}\")\n",
    "                if len(faces) > 1:\n",
    "                    ex = []\n",
    "                    print(type(faces))\n",
    "                    for elem in faces:\n",
    "                        for (x, y, w, h) in [elem]:\n",
    "                            ex.append(frame[y:y + h, x:x + w])\n",
    "\n",
    "                    print(filename)\n",
    "                    plt.figure()\n",
    "                    f, axarr = plt.subplots(4,1)\n",
    "                    axarr[0].imshow(ex[0])\n",
    "                    axarr[1].imshow(ex[1])\n",
    "                    plt.show()\n",
    "\n",
    "                    inp = int(input())\n",
    "                    faces = [faces[inp]]\n",
    "                #     raise Exception(f\"More than 1 faces detected in {filename}\")\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face = frame[y:y + h, x:x + w]\n",
    "\n",
    "                face = cv2.resize(face, (234, 234))\n",
    "                face = face[5:-5, 5:-5]\n",
    "                cv2.imwrite(output_path + '/' + f'{filename}_{count}' + '.png', face)\n",
    "            count += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_all_videos(filenames, paths, skip=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82fea806",
   "metadata": {},
   "source": [
    "### Mean face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08ca70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_tras = {1:1, 2:4, 3:5, 4:0, 5:3, 6:2, 7:6}\n",
    "emotions = {0:'angry', 1:'calm', 2:'disgust', 3:'fear', 4:'happy', 5:'sad', 6:'surprise'}\n",
    "\n",
    "dataset_path = \"Datasets/RAVDESS_frames_face_BW/\"\n",
    "\n",
    "height_orig = 224\n",
    "width_orig = 224\n",
    "height_targ = 112\n",
    "width_targ = 112\n",
    "\n",
    "val_actors = ['19', '20']\n",
    "test_actors = ['21', '22', '23', '24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79c9947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = [] # train\n",
    "\n",
    "for (dirpath, dirnames, fn) in os.walk(dataset_path):\n",
    "    if fn != []:\n",
    "        class_temp = int(fn[0].split('-')[2]) - 1\n",
    "        if class_temp != 0:                                                     # exclude 'neutral' label\n",
    "            if any(act in dirpath for act in (test_actors+val_actors))==False:  # select only train actors\n",
    "                path = [os.path.join(dirpath, elem) for elem in fn]\n",
    "                label = [emotions_tras[class_temp]] * len(fn)                   # emotion transposition\n",
    "                filenames_train.append(list(zip(path, label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "474408f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(list, num_frames_desired):\n",
    "    tot = []\n",
    "    for elem in list:\n",
    "        sampled_list = random.sample(elem, num_frames_desired)\n",
    "        tot += sampled_list\n",
    "    return(tot)\n",
    "\n",
    "\n",
    "def compute_mean_face(filenames):\n",
    "    frames_per_vid = min([len(elem) for elem in filenames])     # number of frames per clip in order to have balanced classes\n",
    "    print(\"frames per video:\", frames_per_vid) \n",
    "\n",
    "    filenames_sampled = sampling(filenames, frames_per_vid)\n",
    "    random.shuffle(filenames_sampled)\n",
    "\n",
    "    faces = []\n",
    "\n",
    "    for path, label in tqdm(filenames_sampled):\n",
    "        face = cv2.imread(path)\n",
    "        face = cv2.resize(face, (112, 112))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        faces.append(face)\n",
    "\n",
    "    faces = np.array(faces)\n",
    "    mean_face = np.mean(faces, axis=0)\n",
    "    mean_face = mean_face/255\n",
    "    mean_face = np.expand_dims(mean_face, axis=2)\n",
    "    np.save('Other/mean_face.npy', mean_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "636a0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames per video: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23184/23184 [00:16<00:00, 1413.38it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_mean_face(filenames_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
